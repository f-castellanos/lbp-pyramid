{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado para un único modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de un único modelo, la aplicación de los datos obtenidos se puede realizar de manera directa.\n",
    "\n",
    "A continuación, se definen variables globales y las librerías que serán empleadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "from preprocess.preprocess import Preprocess\n",
    "from confusion_matrix_pretty_print import print_confusion_matrix\n",
    "\n",
    "\n",
    "# LBP_METHOD = 'default'\n",
    "# LBP_METHOD = 'riu'\n",
    "LBP_METHOD = 'riu2'\n",
    "METHOD = 'get_pyramid_dataset'\n",
    "# METHOD = 'get_datasets_by_scale'\n",
    "HEIGHT = 608"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se cargan las bases de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('jupyter-media/train_train_' + LBP_METHOD + '_' + METHOD + '.pkl')\n",
    "df_test = pd.read_pickle('jupyter-media/train_test_' + LBP_METHOD + '_' + METHOD + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se divide la variable dependiente de las independientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.loc[:, 'label']\n",
    "y_test = df_test.loc[:, 'label']\n",
    "df_train.drop(columns=['label'], inplace=True)\n",
    "df_test.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_clf_and_fit(df, y):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(df, y)\n",
    "    return classifier\n",
    "\n",
    "clf = init_clf_and_fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se realizan las predicciones y obtienen las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6926954950697398\n",
      "\n",
      "F1 score: 0.3522988452412991\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "     t/p      0     1 \n",
      "        0 830053 357492 \n",
      "        1 61274 113888 \n"
     ]
    }
   ],
   "source": [
    "y_predicted = clf.predict(df_test)\n",
    "\n",
    "print('Accuracy score: ' + str(accuracy_score(y_test, y_predicted)) + '\\n')\n",
    "print('F1 score: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "confurion_matrix = confusion_matrix(y_test, y_predicted)\n",
    "print('Confusion matrix:\\n')\n",
    "print_confusion_matrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado para un modelo en cada escala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se recogen los datos y se entrena un modelo para cada escala de la misma forma que en el caso previo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'get_datasets_by_scale'\n",
    "\n",
    "with open('jupyter-media/train_train_' + LBP_METHOD + '_' + METHOD + '.pkl', 'rb') as f:\n",
    "    df_train_list = pickle.load(f)\n",
    "clf_list = [init_clf_and_fit(df_train.iloc[:, :-1], df_train.iloc[:, -1]) for df_train in df_train_list]\n",
    "with open('jupyter-media/train_test_' + LBP_METHOD + '_' + METHOD + '.pkl', 'rb') as f:\n",
    "    df_test_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La aplicación de los modelos resulta algo más compleja. Se recogen las bases de datos correspondientes a cada escala y se aplican los modelos correspondientes. El resultado es un conjunto de predicciones de cada píxel a diferentes resoluciones, por lo que es preciso realizar un mapeo de los píxeles entre sí. Para ello se repiten los píxeles tantas veces como sea preciso para igualar el número de píxeles original de la imagen. Y posteriormente se aplica la máscara en su resolución original con la finalidad de conservar únicamente los píxeles relevantes. Las predicciones se ensamblan mediante un voto por mayoría, es decir se calcula la media de los valores y para aquellos superiores a 0.5 se etiqueta el píxel como perteneciente a un vaso sanguíneo.\n",
    "\n",
    "Como vector de etiquetas reales se recoge el correspondiente a la dimensión original para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_prediction(classifiers, dfs_test):\n",
    "    # Calculating predictions\n",
    "    y_predicted_list = [classifier.predict(test_set.iloc[:, :-1]).reshape(-1, 1)\n",
    "                        for classifier, test_set in zip(classifiers, dfs_test['datasets'])]\n",
    "    # Equaling the number of pixels\n",
    "    y_predicted_list = [y_predicted_list[i].reshape(HEIGHT//(2 ** i), -1) for i in range(len(y_predicted_list))]\n",
    "    y_predicted_list = [Preprocess.repeat_pixels(prediction, (2 ** i))\n",
    "                        for i, prediction in enumerate(y_predicted_list)]\n",
    "    # Mask application\n",
    "    y_predicted_list = [prediction.ravel()[dfs_test['mask']].reshape(-1, 1) for prediction in y_predicted_list]\n",
    "    # print(np.mean(np.concatenate(y_predicted_list, axis=1), axis=0))\n",
    "    # Predictions\n",
    "    y_predictions = np.mean(np.concatenate(y_predicted_list, axis=1), axis=1)\n",
    "    # Actual values\n",
    "    y_actual = np.array(dfs_test['datasets'][0].iloc[:, -1]).ravel()[dfs_test['mask']]\n",
    "    return y_predictions, y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_predicted_test_list = [ensemble_prediction(clf_list, dfs_test) for dfs_test in df_test_list]\n",
    "    y_predicted = np.concatenate([y_predicted_test_pic[0] for y_predicted_test_pic in y_predicted_test_list])\n",
    "    y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "    y_test = np.concatenate([y_predicted_test_pic[1] for y_predicted_test_pic in y_predicted_test_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas que se obtienen son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7937296865723886\n",
      "\n",
      "F1 score: 0.3604006626133178\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "     t/p      0     1 \n",
      "        0 1002428 185117 \n",
      "        1 95969 79193 \n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ' + str(accuracy_score(y_test, y_predicted)) + '\\n')\n",
    "print('F1 score: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print('Confusion matrix:\\n')\n",
    "print_confusion_matrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
